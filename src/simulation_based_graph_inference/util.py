import functools as ft
from matplotlib import pyplot as plt
import networkx as nx
import numpy as np
import numbers
import torch as th
from torch_geometric.data import Data
from torch_geometric.utils.convert import to_scipy_sparse_matrix
import typing


def _plot_generated_graph(generator: typing.Callable, *args, num_nodes: int = 20) -> None:
    """
    Plot a graph generated by the generator.
    """
    seed = 0
    np.random.seed(seed)
    graph = generator(num_nodes, *args)
    fig, ax = plt.subplots()
    pos = nx.spring_layout(graph, seed=seed)
    nx.draw_networkx_edges(graph, pos, edge_color='gray')
    nx.draw_networkx_nodes(graph, pos, node_color='#7fbde9', edgecolors='C0')
    nx.draw_networkx_labels(graph, pos)
    ax.set_aspect('equal')
    ax.set_axis_off()
    fig.tight_layout()


def assert_interval(
        name: str, value: numbers.Number, low: numbers.Number, high: numbers.Number,
        inclusive_low: bool = True, inclusive_high: bool = True, dtype: typing.Type = None) -> None:
    """
    Assert that a value falls in a certain interval and raise a `ValueError` if not.

    Args:
        name: Name of the variable for the error message.
        value: Value to check.
        low: Lower limit of the interval.
        high: Upper limit of the interval.
        inclusive_left: Whether the lower limit of the interval is inclusive.
        inclusive_right: Whether the upper limit of the interval is inclusive.

    Raises:
        ValueError: If the value does not fall in the interval.
    """
    outside = (
        low is not None
        and ((value < low and inclusive_low) or (value <= low and not inclusive_low))
    ) or (
        high is not None
        and ((value > high) and inclusive_high or (value >= high and not inclusive_high))
    )
    if outside:
        raise ValueError(f"{name} must belong to the interval {'[' if inclusive_low else '('}"
                         f"{'-inf' if low is None else low}, {'inf' if high is None else high}"
                         f"{']' if inclusive_high else ')'} but got {value}")
    if dtype:
        value = dtype(value)
    return value


def ensure_long_edge_index(data: Data) -> Data:
    """
    Ensure that the `edge_index` of the data is a long tensor.
    """
    data.edge_index = data.edge_index.to(th.long)
    return data


def assert_normalized_nodel_labels(graph: nx.Graph):
    """
    Assert that node labels are consecutive starting at zero.

    Args:
        graph: Graph whose node labels to check.

    Note:
        This operation is relatively expensive because it makes a copy of the unordered node set.

    Raises:
        ValueError: If the node labels are not normalized.
    """
    if graph is None:
        return nx.Graph()
    if set(graph) != set(range(len(graph))):
        raise ValueError("node labels are not normalized")
    return graph


@ft.wraps(np.random.Generator.integers)
def randint(rng, *args, **kwargs):
    if rng is np.random:
        return rng.randint(*args, **kwargs)
    elif isinstance(rng, np.random.Generator):
        return rng.integers(*args, **kwargs)
    else:
        raise TypeError


def to_edge_index(graph: nx.Graph, edge_index: th.Tensor = None, dtype: th.dtype = th.long) \
        -> th.Tensor:
    """
    Convert a graph to a :mod:`torch_geometric` edge index.

    Args:
        graph: Graph to convert.
        edge_index: Preallocated tensor with shape `(2, 2 * num_edges)`. Defaults to a newly
            allocated tensor.

    Returns:
        edge_index: Tensor with shape `(2, 2 * num_edges)` encoding the edges.

    Raises:
        ValueError: If the preallocated `edge_index` has the wrong shape.
    """
    # Complain about self edges.
    if num_self := nx.number_of_selfloops(graph):
        raise ValueError(f"graph has {num_self} self loops")
    # Prepare memory.
    graph = graph.to_directed()
    expected_shape = (2, graph.number_of_edges())
    if edge_index is None:
        edge_index = th.empty(expected_shape, dtype=dtype)
    elif edge_index.shape != expected_shape:
        raise ValueError(f"expected shape {expected_shape} but got {edge_index.shape}")

    for i, (u, v) in enumerate(graph.to_directed().edges):
        edge_index[0, i] = u
        edge_index[1, i] = v

    return edge_index


class random_sequence:
    """
    Generate an infinite random sequence using a generator efficiently by sampling batches.

    Args:
        generator: Callable to sample a batch of random variables.
        *args: Positional arguments passed to `generator`.
        size: Shape of each sample.
        batch_size: Number of samples per batch.
        **kwargs: Keyword arguments passed to `generator`.
    """
    def __init__(self, generator: typing.Callable, *args, size=None, batch_size: int = 100,
                 **kwargs):
        self.generator = generator
        self.args = args
        self.kwargs = kwargs
        self.batch_size = batch_size
        if size is None:
            self.size = batch_size
        elif isinstance(size, int):
            self.size = (batch_size, size)
        else:
            self.size = (batch_size, *size)
        self.batch = None
        self.iter = None

    def __next__(self):
        try:
            return next(self.iter)
        except (TypeError, StopIteration):
            self.batch = self.generator(*self.args, size=self.size, **self.kwargs)
            self.iter = iter(self.batch)
            return next(self.iter)


def clustering_coefficient(edge_index: th.Tensor, num_nodes: typing.Optional[int] = None) \
        -> th.Tensor:
    """
    Evaluate the local clustering coefficient.

    .. note::

        We calculate the clustering coefficient with scipy sparse matrices because it's an order of
        magnitude faster than sparse torch tensors.

    Args:
        edge_index: Directed edge index.
        num_nodes: Number of nodes in the graph.

    Returns:
        clustering: Clustering coefficient for each node.
    """
    num_nodes = num_nodes or edge_index.max() + 1
    # Count the triangles
    adjacency = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes).tocsr()
    triangles = (adjacency @ adjacency @ adjacency).diagonal()

    # Get the reciprocated degrees.
    reciprocated = adjacency.multiply(adjacency.T).sum(axis=0).A1

    # Evaluate the denominator and clustering coefficient.
    denominator = th.bincount(edge_index[0], minlength=num_nodes) \
        * th.bincount(edge_index[1], minlength=num_nodes) - reciprocated
    return triangles / denominator.clip(min=1)
